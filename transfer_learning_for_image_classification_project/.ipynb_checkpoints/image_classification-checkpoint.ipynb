{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAQ5ZELidcoJ"
   },
   "source": [
    "# 1. Transfer Learning for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skpkWUJEdm6z"
   },
   "source": [
    "### (a) In this problem, we are trying to build a classifier that distinguishes images of 20 bird species. You are provided with text data in twenty folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vob5ooUhqhLJ",
    "outputId": "ddcbdaea-44ba-4068-a7a9-a9c9b6bd14e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Connect to google drive location where input data folder is stored.\n",
    "# Change the path if needed.\n",
    "\n",
    "# File structure for /content/drive/My Drive/mlds_project\n",
    "# mlds_project\n",
    "# -- Data \n",
    "# -- -- Classes.xlsx\n",
    "# -- -- images \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/mlds_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Pkv360pzq4R5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import shutil\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('max_rows', 99999)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "aNmaK5l4q9Mh",
    "outputId": "4a1793ab-a557-4ec9-de4c-804769fba68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not connected to a TPU runtime. Using CPU/GPU strategy\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if tensorflow is using TPU or GPU and print GPU device name\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WZ83MMtO3Hpz"
   },
   "outputs": [],
   "source": [
    "# SSL certificate setup was required for downloading the imagenet weights without SSL error\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_H5o8vdd98s"
   },
   "source": [
    "### (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRWtI2kXePMm"
   },
   "source": [
    "(i) Images in each class are given in separate folders. The file Classes.xlsx provides the classes assigned to the bird species images in each folder. Therefore, you encode your classes using one-hot encoding and Classes.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NLMMzHbTrB50"
   },
   "outputs": [],
   "source": [
    "classes_data = pd.read_excel('Data/Classes.xlsx', engine='openpyxl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8UhLzAtDrES6"
   },
   "outputs": [],
   "source": [
    "output = [[1 if i == j else 0 for i in range(0,20,1)] for j in range(0,20,1)]\n",
    "classes_data[\"onehotencoding\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "Csg0LTVkrGE9",
    "outputId": "6f9dcc36-c0f4-4844-fd2a-08af5a3c7cb3",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a4c7a125-3e3e-4db4-b001-d15193fb67cb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>onehotencoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013.Bobolink</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.Lazuli_Bunting</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023.Brandt_Cormorant</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040.Olive_sided_Flycatcher</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041.Scissor_tailed_Flycatcher</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>067.Anna_Hummingbird</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>072.Pomarine_Jaeger</td>\n",
       "      <td>7</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>076.Dark_eyed_Junco</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>081.Pied_Kingfisher</td>\n",
       "      <td>9</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>082.Ringed_Kingfisher</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "      <td>11</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>099.Ovenbird</td>\n",
       "      <td>12</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104.American_Pipit</td>\n",
       "      <td>13</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>127.Savannah_Sparrow</td>\n",
       "      <td>14</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>135.Bank_Swallow</td>\n",
       "      <td>15</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>141.Artic_Tern</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>149.Brown_Thrasher</td>\n",
       "      <td>17</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>156.White_eyed_Vireo</td>\n",
       "      <td>18</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168.Kentucky_Warbler</td>\n",
       "      <td>19</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4c7a125-3e3e-4db4-b001-d15193fb67cb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a4c7a125-3e3e-4db4-b001-d15193fb67cb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a4c7a125-3e3e-4db4-b001-d15193fb67cb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                     Folder Name   Class  \\\n",
       "0              005.Crested_Auklet      0   \n",
       "1                    013.Bobolink      1   \n",
       "2              015.Lazuli_Bunting      2   \n",
       "3            023.Brandt_Cormorant      3   \n",
       "4      040.Olive_sided_Flycatcher      4   \n",
       "5   041.Scissor_tailed_Flycatcher      5   \n",
       "6            067.Anna_Hummingbird      6   \n",
       "7             072.Pomarine_Jaeger      7   \n",
       "8             076.Dark_eyed_Junco      8   \n",
       "9             081.Pied_Kingfisher      9   \n",
       "10          082.Ringed_Kingfisher     10   \n",
       "11               086.Pacific_Loon     11   \n",
       "12                   099.Ovenbird     12   \n",
       "13             104.American_Pipit     13   \n",
       "14           127.Savannah_Sparrow     14   \n",
       "15               135.Bank_Swallow     15   \n",
       "16                 141.Artic_Tern     16   \n",
       "17             149.Brown_Thrasher     17   \n",
       "18           156.White_eyed_Vireo     18   \n",
       "19           168.Kentucky_Warbler     19   \n",
       "\n",
       "                                                  onehotencoding  \n",
       "0   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4   [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "5   [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "6   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "12  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "17  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbim0E6-AIxA"
   },
   "source": [
    "Folder names specifying the bird name, respective class numbers and one hot encoding can be viewed in above table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdUJErCjgkxO"
   },
   "source": [
    "(ii) Randomly select math.ceil(0.7ni) images from each folder as your training set, math.ceil(0.15ni) as validation set, and the rest as your test set, where ni is the number of images in folder i and dxe is the ceiling of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "1JbqtJ-vrGw_",
    "outputId": "f35d5eee-5207-46e5-8e16-83d871dbeeab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size in each Train, Validation and Test split : \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b0ced14d-114c-447b-a2bc-aa21dd4601c7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>099.Ovenbird</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013.Bobolink</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>023.Brandt_Cormorant</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168.Kentucky_Warbler</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>072.Pomarine_Jaeger</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>040.Olive_sided_Flycatcher</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.American_Pipit</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>067.Anna_Hummingbird</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>082.Ringed_Kingfisher</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127.Savannah_Sparrow</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>076.Dark_eyed_Junco</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>149.Brown_Thrasher</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>041.Scissor_tailed_Flycatcher</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>141.Artic_Tern</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>081.Pied_Kingfisher</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>135.Bank_Swallow</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156.White_eyed_Vireo</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>015.Lazuli_Bunting</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0ced14d-114c-447b-a2bc-aa21dd4601c7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b0ced14d-114c-447b-a2bc-aa21dd4601c7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b0ced14d-114c-447b-a2bc-aa21dd4601c7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                      folder_name train validation test total\n",
       "0                    099.Ovenbird    42          9    9    60\n",
       "1                    013.Bobolink    42          9    9    60\n",
       "2            023.Brandt_Cormorant    42          9    8    59\n",
       "3            168.Kentucky_Warbler    42          9    8    59\n",
       "4             072.Pomarine_Jaeger    42          9    9    60\n",
       "5      040.Olive_sided_Flycatcher    42          9    9    60\n",
       "6              104.American_Pipit    42          9    9    60\n",
       "7            067.Anna_Hummingbird    42          9    9    60\n",
       "8           082.Ringed_Kingfisher    42          9    9    60\n",
       "9            127.Savannah_Sparrow    42          9    9    60\n",
       "10            076.Dark_eyed_Junco    42          9    9    60\n",
       "11             149.Brown_Thrasher    42          9    8    59\n",
       "12  041.Scissor_tailed_Flycatcher    42          9    9    60\n",
       "13                 141.Artic_Tern    41          9    8    58\n",
       "14               086.Pacific_Loon    42          9    9    60\n",
       "15            081.Pied_Kingfisher    42          9    9    60\n",
       "16               135.Bank_Swallow    42          9    8    59\n",
       "17           156.White_eyed_Vireo    42          9    9    60\n",
       "18             005.Crested_Auklet    31          7    6    44\n",
       "19             015.Lazuli_Bunting    41          9    8    58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Images in each class folder are split into train, validation and test. \n",
    "# The split happens randomly and is done based on the numbers given in question prompt\n",
    "\n",
    "folder_prefix = \"Data/images/\"\n",
    "folder_names = classes_data['Folder Name '].tolist()\n",
    "folders = os.listdir(folder_prefix)\n",
    "\n",
    "random.seed(42)\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "dataset_split = pd.DataFrame(columns=['folder_name','train','validation','test','total'])\n",
    "\n",
    "for folder in folders:\n",
    "    if folder in folder_names:\n",
    "        path = folder_prefix + folder\n",
    "        \n",
    "        train_path = path + \"/train\"\n",
    "        if os.path.exists(train_path):\n",
    "            shutil.rmtree(train_path)\n",
    "        os.makedirs(train_path)\n",
    "          \n",
    "        test_path = path + \"/test\"\n",
    "        if os.path.exists(test_path):\n",
    "            shutil.rmtree(test_path)\n",
    "        os.makedirs(test_path)\n",
    "        \n",
    "        val_path = path + \"/val\"\n",
    "        if os.path.exists(val_path):\n",
    "            shutil.rmtree(val_path)\n",
    "        os.makedirs(val_path)\n",
    "        \n",
    "        files = os.listdir(path)\n",
    "        files = [item for item in files if \"jpg\" in item]\n",
    "        ni = len(files)\n",
    "        \n",
    "        train_split = random.sample(files, math.ceil(0.7 * ni))\n",
    "        files = [item for item in files if item not in train_split]\n",
    "        val_split = random.sample(files, math.ceil(0.15 * ni))\n",
    "        test_split = [item for item in files if item not in val_split]\n",
    "        \n",
    "        prefix_ADD = path + \"/\"\n",
    "        train_split = [prefix_ADD + x for x in train_split if not str(x) == \"nan\"]\n",
    "        val_split = [prefix_ADD + x for x in val_split if not str(x) == \"nan\"]\n",
    "        test_split = [prefix_ADD + x for x in test_split if not str(x) == \"nan\"]\n",
    "        train_files.extend(train_split)\n",
    "        val_files.extend(val_split)\n",
    "        test_files.extend(test_split)\n",
    "        dataset_split = dataset_split.append({'folder_name': folder, 'train': len(train_split), 'validation': len(val_split), 'test': len(test_split), 'total': ni}, ignore_index=True)\n",
    "\n",
    "print(\"Data size in each Train, Validation and Test split : \")\n",
    "print(\"\\n\")\n",
    "dataset_split.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0SmyAwBhOoZ"
   },
   "source": [
    "(iii) In order for all the images to have the same size, zero-pad or resize the images in your dataset. This can be done using various tools, including OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jQ9hKa1srKyT"
   },
   "outputs": [],
   "source": [
    "# Image resizing was performed using OpenCV. All images were resized to 224*224. \n",
    "# Resized images are stored in train, val and test folders with each image class folder.\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "dim = (width, height)\n",
    "\n",
    "updated_train_files = []\n",
    "updated_val_files = []\n",
    "updated_test_files = []\n",
    "\n",
    "def resize_image(image, split_type):\n",
    "    img = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "    resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    path_split = image.rsplit('/', 1)\n",
    "    cv2.imwrite(path_split[0] + \"/\" + split_type + \"/\" + path_split[1], resized_img)\n",
    "    \n",
    "for image in train_files:\n",
    "    split_type = \"train\"\n",
    "    resize_image(image, split_type)\n",
    "    path_split = image.rsplit('/', 1)\n",
    "    updated_train_files.append(path_split[0] + \"/\" + split_type + \"/\" + path_split[1])\n",
    "\n",
    "for image in val_files:\n",
    "    split_type = \"val\"\n",
    "    resize_image(image, split_type)\n",
    "    path_split = image.rsplit('/', 1)\n",
    "    updated_val_files.append(path_split[0] + \"/\" + split_type + \"/\" + path_split[1])\n",
    "    \n",
    "for image in test_files:\n",
    "    split_type = \"test\"\n",
    "    resize_image(image, split_type)\n",
    "    path_split = image.rsplit('/', 1)\n",
    "    updated_test_files.append(path_split[0] + \"/\" + split_type + \"/\" + path_split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN03Hw90hVWm"
   },
   "source": [
    "### (c) Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lOV9Z4whtns"
   },
   "source": [
    "(i) When dealing with classification of relatively small image datasets, deep networks may not perform very well because of not having enough data to train\n",
    "them. In such cases, one usually uses transfer learning, which uses deep\n",
    "learning models that are trained on very large datasets such as ImageNet\n",
    "as feature extractors. The idea is that such deep networks have learned to\n",
    "extract meaningful features from an image using their layers, and those fea-\n",
    "tures can be used in learning other tasks. In order to do that, usually the\n",
    "last layer or the last few layers of the pre-trained network are removed, and\n",
    "the response of the layer before the removed layers to the images in the new\n",
    "dataset is used as a feature vector to train one more multiple replacement layers. The dataset in this task has only around 50-60 images per class. Given\n",
    "that we have 20 classes, training a deep network with such a small dataset\n",
    "may not yield desirable results. In this project, you will use pre-trained models EfficientNetB0 and VGG16. For both pre-trained networks, you will only\n",
    "train the last fully connected layer, and will freeze all layers before them (i.e. we do not change their parameters during training) and use the outputs of the penultimate layer in the original pre-trained model as the features extracted from each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e-2ZQsO4rfCZ"
   },
   "outputs": [],
   "source": [
    "label_encoding = dict(zip(classes_data[\"Folder Name \"], classes_data[\"onehotencoding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FznyZEicrcxm"
   },
   "outputs": [],
   "source": [
    "# Read each image from train, val and test folders into numpy array \n",
    "# and extract their associated one hot encoding labels\n",
    "np_train = []\n",
    "np_val = []\n",
    "np_test = []\n",
    "\n",
    "np_train_label = []\n",
    "np_val_label = []\n",
    "np_test_label = []\n",
    "\n",
    "def prepare_data(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "for folder in folders:\n",
    "    if folder in folder_names:\n",
    "        path = folder_prefix + folder\n",
    "        \n",
    "        train_path = path + \"/train\"\n",
    "        test_path = path + \"/test\"\n",
    "        val_path = path + \"/val\"\n",
    "        \n",
    "        files = os.listdir(train_path)\n",
    "        for file in files:\n",
    "            img = prepare_data(train_path + \"/\" + file)\n",
    "            np_train.append(img)\n",
    "            np_train_label.append(label_encoding[folder])\n",
    "\n",
    "        files = os.listdir(val_path)\n",
    "        for file in files:\n",
    "            img = prepare_data(val_path + \"/\" + file)\n",
    "            np_val.append(img)\n",
    "            np_val_label.append(label_encoding[folder])\n",
    "            \n",
    "        files = os.listdir(test_path)\n",
    "        for file in files:\n",
    "            img = prepare_data(test_path + \"/\" + file)\n",
    "            np_test.append(img)\n",
    "            np_test_label.append(label_encoding[folder])\n",
    "            \n",
    "ds_train = np.stack(np_train, 0)\n",
    "ds_val = np.stack(np_val, 0)\n",
    "ds_test = np.stack(np_test, 0)\n",
    "\n",
    "ds_train_label = np.array([np.array(xi) for xi in np_train_label])\n",
    "ds_val_label = np.array([np.array(xi) for xi in np_val_label])\n",
    "ds_test_label = np.array([np.array(xi) for xi in np_test_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt2qwolSh3WN"
   },
   "source": [
    "(ii) To perform empirical regularization, crop, randomly zoo, rotate, flip, contrast, and translate images in your training set for image augmentation. You can use various tools to do this, including OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZnczebHUrQt9"
   },
   "outputs": [],
   "source": [
    "# Augmentation is performed using ImageDataGenerator\n",
    "# All the augmentation techniques mentioned in question prompt are applied to the training data\n",
    "augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "      layers.RandomCrop(height=224,width=224),\n",
    "      layers.RandomContrast(0.2)\n",
    "    ],\n",
    "    name=\"crop_contrast_augmentation\"\n",
    ")\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.2,1.2],\n",
    "        preprocessing_function = augmentation,\n",
    "        channel_shift_range=100,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGUZLMVwjOyG"
   },
   "source": [
    "### **EFFICIENTNETB0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fylo7d7ViDia"
   },
   "source": [
    "(iii) Use ReLU activation functions in the last layer and a softmax layer, along with batch normalization 4 and a dropout rate of 20% as well as ADAM optimizer. Use multinomial cross entropy loss. You can try any batch size,\n",
    "but a batch size of 5 seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwnUsVbQu_qI"
   },
   "source": [
    "Model structure is kept same as what was mentioned in homework description -\n",
    "1. Model top(last) layer is dropped\n",
    "2. Model weights are frozen for all existing layers\n",
    "3. A dense layer is added and the output classes are reduced to 20\n",
    "4. Batch Normalization is performed\n",
    "5. Relu activation\n",
    "6. Drop out with rop out rate of 20%\n",
    "7. Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJkJS8Lcrf9O",
    "outputId": "78ddf4e1-d261-46e6-d6dc-1726505d28fe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNetB0\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               N          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                N          \n",
      "                                                                                                             \n",
      " normalization (Normalization)  (None, 224, 224, 3)  7           ['rescaling[0][0]']              N          \n",
      "                                                                                                             \n",
      " tf.math.truediv (TFOpLambda)   (None, 224, 224, 3)  0           ['normalization[0][0]']          N          \n",
      "                                                                                                             \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['tf.math.truediv[0][0]']        N          \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        N          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         N          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             N          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     N          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   N          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    N          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      N          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][  N          \n",
      " g2D)                           )                                0]']                                        \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     N          \n",
      " D)                                                                                                          \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     N          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     N          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           N          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][  N          \n",
      " g2D)                                                            0]']                                        \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     N          \n",
      " D)                                                                                                          \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     N          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     N          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           N          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][  N          \n",
      " g2D)                                                            0]']                                        \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     N          \n",
      " D)                                                                                                          \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     N          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     N          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           N          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     N          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           N          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     N          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     N          \n",
      "                                                                  'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           N          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     N          \n",
      "                                                                  'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           N          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][  N          \n",
      " g2D)                                                            0]']                                        \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     N          \n",
      " D)                                                                                                          \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     N          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     N          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           N          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     N          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           N          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     N          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           N          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      N          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][  N          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             N          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     N          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     N          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     N          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      N          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     N          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      N          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     N          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               N          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 N          \n",
      "                                                                                                             \n",
      " avg_pool (GlobalAveragePooling  (None, 1280)        0           ['top_activation[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " top_dropout (Dropout)          (None, 1280)         0           ['avg_pool[0][0]']               Y          \n",
      "                                                                                                             \n",
      " dense (Dense)                  (None, 20)           25620       ['top_dropout[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization (BatchNorm  (None, 20)          80          ['dense[0][0]']                  Y          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " re_lu (ReLU)                   (None, 20)           0           ['batch_normalization[0][0]']    Y          \n",
      "                                                                                                             \n",
      " softmax (Softmax)              (None, 20)           0           ['re_lu[0][0]']                  Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 4,075,271\n",
      "Trainable params: 25,660\n",
      "Non-trainable params: 4,049,611\n",
      "_____________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "def efficientnet_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights='imagenet')\n",
    "    model.trainable = False\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    x = layers.Dense(num_classes, name=\"dense\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    outputs = layers.Softmax()(x)\n",
    "    mymodel = tf.keras.Model(inputs, outputs, name=\"EfficientNetB0\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-3)\n",
    "    mymodel.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], steps_per_execution = 1\n",
    "    )\n",
    "    return mymodel\n",
    "\n",
    "with strategy.scope():\n",
    "    efficientmodel = efficientnet_model(num_classes=20)\n",
    "efficientmodel.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0FjK9kDAIxD"
   },
   "source": [
    "The above is model summary. It lists all the layers of EfficientNetB0 and the modified last dense layer. It also lists which layers are trainable and which arent in last column. We can see that only the last dense layer added which includes GlobalAveragePooling, Dropout, Dense, Batch Normalization, ReLU and Softmax are trainable (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlAZ040Ribqc"
   },
   "source": [
    "(iv) Train the networks (EfficientNetB0 and VGG16) for at least 50 epochs\n",
    "(preferably 100 epochs) and perform early stopping using the validation set.\n",
    "Keep the network parameters that have the lowest validation error. Plot the\n",
    "training and validation errors vs. epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBMso4W3rhtf",
    "outputId": "6bf8e1a3-0abf-405f-cfec-4da6cbdfc051",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 34s - loss: 2.4677 - accuracy: 0.3023 - val_loss: 1.6357 - val_accuracy: 0.7416 - 34s/epoch - 2s/step\n",
      "Epoch 2/100\n",
      "17/17 - 19s - loss: 1.6347 - accuracy: 0.6638 - val_loss: 1.0843 - val_accuracy: 0.8539 - 19s/epoch - 1s/step\n",
      "Epoch 3/100\n",
      "17/17 - 21s - loss: 1.3925 - accuracy: 0.7255 - val_loss: 0.9054 - val_accuracy: 0.8427 - 21s/epoch - 1s/step\n",
      "Epoch 4/100\n",
      "17/17 - 20s - loss: 1.2761 - accuracy: 0.7678 - val_loss: 0.8155 - val_accuracy: 0.8820 - 20s/epoch - 1s/step\n",
      "Epoch 5/100\n",
      "17/17 - 20s - loss: 1.1873 - accuracy: 0.7920 - val_loss: 0.7548 - val_accuracy: 0.8876 - 20s/epoch - 1s/step\n",
      "Epoch 6/100\n",
      "17/17 - 20s - loss: 1.0852 - accuracy: 0.8138 - val_loss: 0.7281 - val_accuracy: 0.8989 - 20s/epoch - 1s/step\n",
      "Epoch 7/100\n",
      "17/17 - 20s - loss: 1.0635 - accuracy: 0.8065 - val_loss: 0.6811 - val_accuracy: 0.8933 - 20s/epoch - 1s/step\n",
      "Epoch 8/100\n",
      "17/17 - 20s - loss: 0.9508 - accuracy: 0.8464 - val_loss: 0.6445 - val_accuracy: 0.9045 - 20s/epoch - 1s/step\n",
      "Epoch 9/100\n",
      "17/17 - 19s - loss: 0.9302 - accuracy: 0.8380 - val_loss: 0.6296 - val_accuracy: 0.8876 - 19s/epoch - 1s/step\n",
      "Epoch 10/100\n",
      "17/17 - 19s - loss: 0.8925 - accuracy: 0.8440 - val_loss: 0.6082 - val_accuracy: 0.8989 - 19s/epoch - 1s/step\n",
      "Epoch 11/100\n",
      "17/17 - 19s - loss: 0.8547 - accuracy: 0.8609 - val_loss: 0.5741 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 12/100\n",
      "17/17 - 20s - loss: 0.7965 - accuracy: 0.8742 - val_loss: 0.5749 - val_accuracy: 0.8933 - 20s/epoch - 1s/step\n",
      "Epoch 13/100\n",
      "17/17 - 19s - loss: 0.7628 - accuracy: 0.8730 - val_loss: 0.5334 - val_accuracy: 0.9045 - 19s/epoch - 1s/step\n",
      "Epoch 14/100\n",
      "17/17 - 19s - loss: 0.7365 - accuracy: 0.8730 - val_loss: 0.5195 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 15/100\n",
      "17/17 - 19s - loss: 0.7613 - accuracy: 0.8440 - val_loss: 0.5130 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 16/100\n",
      "17/17 - 19s - loss: 0.6751 - accuracy: 0.8791 - val_loss: 0.4896 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 17/100\n",
      "17/17 - 19s - loss: 0.6909 - accuracy: 0.8706 - val_loss: 0.4851 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 18/100\n",
      "17/17 - 19s - loss: 0.6953 - accuracy: 0.8597 - val_loss: 0.4737 - val_accuracy: 0.8989 - 19s/epoch - 1s/step\n",
      "Epoch 19/100\n",
      "17/17 - 19s - loss: 0.6289 - accuracy: 0.8900 - val_loss: 0.4604 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 20/100\n",
      "17/17 - 19s - loss: 0.6129 - accuracy: 0.8900 - val_loss: 0.4763 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 21/100\n",
      "17/17 - 19s - loss: 0.6336 - accuracy: 0.8839 - val_loss: 0.4639 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 22/100\n",
      "17/17 - 19s - loss: 0.6166 - accuracy: 0.8803 - val_loss: 0.4375 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 23/100\n",
      "17/17 - 19s - loss: 0.5974 - accuracy: 0.8779 - val_loss: 0.4244 - val_accuracy: 0.9045 - 19s/epoch - 1s/step\n",
      "Epoch 24/100\n",
      "17/17 - 19s - loss: 0.5732 - accuracy: 0.8863 - val_loss: 0.4324 - val_accuracy: 0.9045 - 19s/epoch - 1s/step\n",
      "Epoch 25/100\n",
      "17/17 - 20s - loss: 0.5450 - accuracy: 0.8863 - val_loss: 0.4583 - val_accuracy: 0.9157 - 20s/epoch - 1s/step\n",
      "Epoch 26/100\n",
      "17/17 - 19s - loss: 0.5577 - accuracy: 0.8827 - val_loss: 0.4169 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 27/100\n",
      "17/17 - 19s - loss: 0.5389 - accuracy: 0.8936 - val_loss: 0.4079 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 28/100\n",
      "17/17 - 19s - loss: 0.5348 - accuracy: 0.8996 - val_loss: 0.4014 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 29/100\n",
      "17/17 - 19s - loss: 0.5344 - accuracy: 0.8948 - val_loss: 0.4067 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 30/100\n",
      "17/17 - 19s - loss: 0.5408 - accuracy: 0.8827 - val_loss: 0.4103 - val_accuracy: 0.9045 - 19s/epoch - 1s/step\n",
      "Epoch 31/100\n",
      "17/17 - 19s - loss: 0.5019 - accuracy: 0.9057 - val_loss: 0.3998 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 32/100\n",
      "17/17 - 19s - loss: 0.4723 - accuracy: 0.9081 - val_loss: 0.3992 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 33/100\n",
      "17/17 - 19s - loss: 0.4889 - accuracy: 0.8924 - val_loss: 0.3989 - val_accuracy: 0.9157 - 19s/epoch - 1s/step\n",
      "Epoch 34/100\n",
      "17/17 - 19s - loss: 0.4803 - accuracy: 0.9033 - val_loss: 0.3838 - val_accuracy: 0.9101 - 19s/epoch - 1s/step\n",
      "Epoch 35/100\n",
      "17/17 - 19s - loss: 0.5034 - accuracy: 0.8924 - val_loss: 0.4198 - val_accuracy: 0.8989 - 19s/epoch - 1s/step\n",
      "Epoch 36/100\n",
      "17/17 - 18s - loss: 0.4424 - accuracy: 0.9129 - val_loss: 0.4223 - val_accuracy: 0.8933 - 18s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Early stopping is being performed on val_accuracy with mode max. This means the metric being monitored is \n",
    "# validation accuracy(or validation error) and on max(or min) value of it. restore_best_weights selects the model with max validation accuracy. \n",
    "# This ensures that best model is the one with lowest validation error (1-accuracy)\n",
    "\n",
    "epochs = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience = 20, restore_best_weights=True, mode = \"max\")\n",
    "hist_efficient = efficientmodel.fit(datagen.flow(ds_train, ds_train_label, batch_size=50), \n",
    "                           epochs=epochs, validation_data=(ds_val, ds_val_label), \n",
    "                           verbose=2, \n",
    "                           batch_size = 50,\n",
    "                           callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "_sW67mpFrkf4",
    "outputId": "7de9cfa8-e637-4bc1-b77e-693c370a794a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist_error(hist):\n",
    "    train_error = [1-x for x in hist.history[\"accuracy\"]]\n",
    "    val_error = [1-x for x in hist.history[\"val_accuracy\"]]\n",
    "    plt.plot(train_error)\n",
    "    plt.plot(val_error)\n",
    "    plt.title(\"model error\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hist_error(hist_efficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJUlInEaimHw"
   },
   "source": [
    "(v) Report Precision, Recall, and F1 score for your model. Remember that this\n",
    "is a multi-class classfication problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YKZSfTbYrmS-"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, ds_test, ds_test_label):\n",
    "    labels = model.predict(ds_test)\n",
    "    max_index = np.argmax(labels, axis=1)\n",
    "    ds_test_index = np.argmax(ds_test_label, axis=1)\n",
    "    \n",
    "    y_pred = max_index.tolist()\n",
    "    y_true = ds_test_index.tolist()\n",
    "    target_names = classes_data['Folder Name '].tolist()\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EseBoh6j9Nv"
   },
   "source": [
    "##### Train metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8zRYYP5iqtv",
    "outputId": "fe25c37f-d8e3-4e9a-eeff-6e6abf0d1430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 5s 57ms/step\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           005.Crested_Auklet       1.00      1.00      1.00        31\n",
      "                 013.Bobolink       1.00      0.98      0.99        42\n",
      "           015.Lazuli_Bunting       1.00      1.00      1.00        41\n",
      "         023.Brandt_Cormorant       1.00      0.95      0.98        42\n",
      "   040.Olive_sided_Flycatcher       0.98      0.95      0.96        42\n",
      "041.Scissor_tailed_Flycatcher       1.00      0.98      0.99        42\n",
      "         067.Anna_Hummingbird       1.00      1.00      1.00        42\n",
      "          072.Pomarine_Jaeger       0.98      1.00      0.99        42\n",
      "          076.Dark_eyed_Junco       0.95      1.00      0.98        42\n",
      "          081.Pied_Kingfisher       1.00      0.98      0.99        42\n",
      "        082.Ringed_Kingfisher       1.00      1.00      1.00        42\n",
      "             086.Pacific_Loon       0.98      1.00      0.99        42\n",
      "                 099.Ovenbird       1.00      0.95      0.98        42\n",
      "           104.American_Pipit       0.98      0.95      0.96        42\n",
      "         127.Savannah_Sparrow       0.91      1.00      0.95        42\n",
      "             135.Bank_Swallow       0.98      0.98      0.98        42\n",
      "               141.Artic_Tern       1.00      1.00      1.00        41\n",
      "           149.Brown_Thrasher       1.00      1.00      1.00        42\n",
      "         156.White_eyed_Vireo       0.98      1.00      0.99        42\n",
      "         168.Kentucky_Warbler       1.00      1.00      1.00        42\n",
      "\n",
      "                     accuracy                           0.99       827\n",
      "                    macro avg       0.99      0.99      0.99       827\n",
      "                 weighted avg       0.99      0.99      0.99       827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(efficientmodel, ds_train, ds_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiSSPV6Yj_BX"
   },
   "source": [
    "##### Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRSy8ERUroA5",
    "outputId": "d25ae022-0ddd-416c-ab76-ff993243e2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 141ms/step\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           005.Crested_Auklet       1.00      1.00      1.00         6\n",
      "                 013.Bobolink       1.00      1.00      1.00         9\n",
      "           015.Lazuli_Bunting       1.00      1.00      1.00         8\n",
      "         023.Brandt_Cormorant       1.00      1.00      1.00         8\n",
      "   040.Olive_sided_Flycatcher       0.80      0.89      0.84         9\n",
      "041.Scissor_tailed_Flycatcher       0.86      0.67      0.75         9\n",
      "         067.Anna_Hummingbird       1.00      1.00      1.00         9\n",
      "          072.Pomarine_Jaeger       0.82      1.00      0.90         9\n",
      "          076.Dark_eyed_Junco       1.00      1.00      1.00         9\n",
      "          081.Pied_Kingfisher       1.00      0.89      0.94         9\n",
      "        082.Ringed_Kingfisher       1.00      0.89      0.94         9\n",
      "             086.Pacific_Loon       1.00      1.00      1.00         9\n",
      "                 099.Ovenbird       0.89      0.89      0.89         9\n",
      "           104.American_Pipit       0.80      0.89      0.84         9\n",
      "         127.Savannah_Sparrow       0.90      1.00      0.95         9\n",
      "             135.Bank_Swallow       0.71      0.62      0.67         8\n",
      "               141.Artic_Tern       1.00      1.00      1.00         8\n",
      "           149.Brown_Thrasher       0.86      0.75      0.80         8\n",
      "         156.White_eyed_Vireo       0.78      0.78      0.78         9\n",
      "         168.Kentucky_Warbler       0.78      0.88      0.82         8\n",
      "\n",
      "                     accuracy                           0.91       171\n",
      "                    macro avg       0.91      0.91      0.91       171\n",
      "                 weighted avg       0.91      0.91      0.91       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(efficientmodel, ds_test, ds_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9PYDf__i4yV"
   },
   "source": [
    "### **VGG16**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4S1WWrMjEjI"
   },
   "source": [
    "(iii) Use ReLU activation functions in the last layer and a softmax layer, along with batch normalization 4 and a dropout rate of 20% as well as ADAM optimizer. Use multinomial cross entropy loss. You can try any batch size,\n",
    "but a batch size of 5 seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCAPmsaIvDBe"
   },
   "source": [
    "Model structure is kept same as what was mentioned in homework description -\n",
    "1. Model top(last) layer is dropped\n",
    "2. Model weights are frozen for all existing layers\n",
    "3. A dense layer is added and the output classes are reduced to 20\n",
    "4. Batch Normalization is performed\n",
    "5. Relu activation\n",
    "6. Drop out with rop out rate of 20%\n",
    "7. Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sW9gaYMeV1Hq",
    "outputId": "bc80ede7-a8b2-4d63-d04d-307d18ee1e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         N          \n",
      "                                                                            \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      N          \n",
      "                                                                            \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     N          \n",
      "                                                                            \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         N          \n",
      "                                                                            \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     N          \n",
      "                                                                            \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    N          \n",
      "                                                                            \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         N          \n",
      "                                                                            \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    N          \n",
      "                                                                            \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    N          \n",
      "                                                                            \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    N          \n",
      "                                                                            \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         N          \n",
      "                                                                            \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   N          \n",
      "                                                                            \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   N          \n",
      "                                                                            \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   N          \n",
      "                                                                            \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         N          \n",
      "                                                                            \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   N          \n",
      "                                                                            \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   N          \n",
      "                                                                            \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   N          \n",
      "                                                                            \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         N          \n",
      "                                                                            \n",
      " avg_pool (GlobalAveragePool  (None, 512)              0         Y          \n",
      " ing2D)                                                                     \n",
      "                                                                            \n",
      " top_dropout (Dropout)       (None, 512)               0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 20)                10260     Y          \n",
      "                                                                            \n",
      " batch_normalization_1 (Batc  (None, 20)               80        Y          \n",
      " hNormalization)                                                            \n",
      "                                                                            \n",
      " re_lu_1 (ReLU)              (None, 20)                0         Y          \n",
      "                                                                            \n",
      " softmax_1 (Softmax)         (None, 20)                0         Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 14,725,028\n",
      "Trainable params: 10,300\n",
      "Non-trainable params: 14,714,728\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "def vgg16_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = VGG16(include_top=False, input_tensor=inputs, weights='imagenet')\n",
    "    model.trainable = False\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    x = layers.Dense(num_classes, name=\"dense\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    outputs = layers.Softmax()(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"VGG16\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-3)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], steps_per_execution = 1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    vgg_model = vgg16_model(num_classes=20)\n",
    "vgg_model.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMiA0aYeAIxF"
   },
   "source": [
    "The above is model summary. It lists all the layers of VGG16 and the modified last dense layer. It also lists which layers are trainable and which arent in last column. We can see that only the last dense layer added which includes GlobalAveragePooling, Dropout, Dense, Batch Normalization, ReLU and Softmax are trainable (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLRpFpvCjmmF"
   },
   "source": [
    "(iv) Train the networks (EfficientNetB0 and VGG16) for at least 50 epochs\n",
    "(preferably 100 epochs) and perform early stopping using the validation set.\n",
    "Keep the network parameters that have the lowest validation error. Plot the\n",
    "training and validation errors vs. epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aqM9dHyWfhs",
    "outputId": "76a85963-3667-4efe-be32-f43b4e9f31a6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 35s - loss: 3.0861 - accuracy: 0.0593 - val_loss: 3.0356 - val_accuracy: 0.0562 - 35s/epoch - 2s/step\n",
      "Epoch 2/100\n",
      "17/17 - 21s - loss: 2.9735 - accuracy: 0.0955 - val_loss: 2.8980 - val_accuracy: 0.1348 - 21s/epoch - 1s/step\n",
      "Epoch 3/100\n",
      "17/17 - 22s - loss: 2.9274 - accuracy: 0.1112 - val_loss: 2.7348 - val_accuracy: 0.1910 - 22s/epoch - 1s/step\n",
      "Epoch 4/100\n",
      "17/17 - 22s - loss: 2.8781 - accuracy: 0.1282 - val_loss: 2.5737 - val_accuracy: 0.2921 - 22s/epoch - 1s/step\n",
      "Epoch 5/100\n",
      "17/17 - 22s - loss: 2.8005 - accuracy: 0.1826 - val_loss: 2.5870 - val_accuracy: 0.3596 - 22s/epoch - 1s/step\n",
      "Epoch 6/100\n",
      "17/17 - 22s - loss: 2.6932 - accuracy: 0.2104 - val_loss: 2.1881 - val_accuracy: 0.4438 - 22s/epoch - 1s/step\n",
      "Epoch 7/100\n",
      "17/17 - 21s - loss: 2.6326 - accuracy: 0.2358 - val_loss: 1.9430 - val_accuracy: 0.4888 - 21s/epoch - 1s/step\n",
      "Epoch 8/100\n",
      "17/17 - 21s - loss: 2.6174 - accuracy: 0.2322 - val_loss: 1.7400 - val_accuracy: 0.5449 - 21s/epoch - 1s/step\n",
      "Epoch 9/100\n",
      "17/17 - 22s - loss: 2.5247 - accuracy: 0.2696 - val_loss: 1.7176 - val_accuracy: 0.5674 - 22s/epoch - 1s/step\n",
      "Epoch 10/100\n",
      "17/17 - 22s - loss: 2.4826 - accuracy: 0.2576 - val_loss: 1.6786 - val_accuracy: 0.6067 - 22s/epoch - 1s/step\n",
      "Epoch 11/100\n",
      "17/17 - 22s - loss: 2.4208 - accuracy: 0.2866 - val_loss: 1.3624 - val_accuracy: 0.6292 - 22s/epoch - 1s/step\n",
      "Epoch 12/100\n",
      "17/17 - 22s - loss: 2.4160 - accuracy: 0.2793 - val_loss: 1.1574 - val_accuracy: 0.6742 - 22s/epoch - 1s/step\n",
      "Epoch 13/100\n",
      "17/17 - 22s - loss: 2.3848 - accuracy: 0.3047 - val_loss: 1.0889 - val_accuracy: 0.6910 - 22s/epoch - 1s/step\n",
      "Epoch 14/100\n",
      "17/17 - 22s - loss: 2.3743 - accuracy: 0.3108 - val_loss: 1.0776 - val_accuracy: 0.6854 - 22s/epoch - 1s/step\n",
      "Epoch 15/100\n",
      "17/17 - 22s - loss: 2.3416 - accuracy: 0.3011 - val_loss: 1.0565 - val_accuracy: 0.7135 - 22s/epoch - 1s/step\n",
      "Epoch 16/100\n",
      "17/17 - 21s - loss: 2.3386 - accuracy: 0.3204 - val_loss: 1.0581 - val_accuracy: 0.6910 - 21s/epoch - 1s/step\n",
      "Epoch 17/100\n",
      "17/17 - 22s - loss: 2.3380 - accuracy: 0.3156 - val_loss: 1.0124 - val_accuracy: 0.7135 - 22s/epoch - 1s/step\n",
      "Epoch 18/100\n",
      "17/17 - 21s - loss: 2.2726 - accuracy: 0.3277 - val_loss: 0.9229 - val_accuracy: 0.7303 - 21s/epoch - 1s/step\n",
      "Epoch 19/100\n",
      "17/17 - 21s - loss: 2.2785 - accuracy: 0.3289 - val_loss: 1.0349 - val_accuracy: 0.7135 - 21s/epoch - 1s/step\n",
      "Epoch 20/100\n",
      "17/17 - 22s - loss: 2.3040 - accuracy: 0.3362 - val_loss: 1.0805 - val_accuracy: 0.7079 - 22s/epoch - 1s/step\n",
      "Epoch 21/100\n",
      "17/17 - 21s - loss: 2.2258 - accuracy: 0.3422 - val_loss: 1.0429 - val_accuracy: 0.7191 - 21s/epoch - 1s/step\n",
      "Epoch 22/100\n",
      "17/17 - 21s - loss: 2.2648 - accuracy: 0.3337 - val_loss: 0.9366 - val_accuracy: 0.7416 - 21s/epoch - 1s/step\n",
      "Epoch 23/100\n",
      "17/17 - 21s - loss: 2.2583 - accuracy: 0.3241 - val_loss: 0.9754 - val_accuracy: 0.7640 - 21s/epoch - 1s/step\n",
      "Epoch 24/100\n",
      "17/17 - 21s - loss: 2.2465 - accuracy: 0.3434 - val_loss: 0.9220 - val_accuracy: 0.7528 - 21s/epoch - 1s/step\n",
      "Epoch 25/100\n",
      "17/17 - 21s - loss: 2.2510 - accuracy: 0.3434 - val_loss: 0.9378 - val_accuracy: 0.7416 - 21s/epoch - 1s/step\n",
      "Epoch 26/100\n",
      "17/17 - 21s - loss: 2.2066 - accuracy: 0.3507 - val_loss: 0.9125 - val_accuracy: 0.7584 - 21s/epoch - 1s/step\n",
      "Epoch 27/100\n",
      "17/17 - 21s - loss: 2.2468 - accuracy: 0.3628 - val_loss: 1.0872 - val_accuracy: 0.7247 - 21s/epoch - 1s/step\n",
      "Epoch 28/100\n",
      "17/17 - 22s - loss: 2.1708 - accuracy: 0.3664 - val_loss: 1.0941 - val_accuracy: 0.7191 - 22s/epoch - 1s/step\n",
      "Epoch 29/100\n",
      "17/17 - 21s - loss: 2.1926 - accuracy: 0.3519 - val_loss: 0.9655 - val_accuracy: 0.7360 - 21s/epoch - 1s/step\n",
      "Epoch 30/100\n",
      "17/17 - 22s - loss: 2.2266 - accuracy: 0.3337 - val_loss: 0.9311 - val_accuracy: 0.7472 - 22s/epoch - 1s/step\n",
      "Epoch 31/100\n",
      "17/17 - 21s - loss: 2.1816 - accuracy: 0.3446 - val_loss: 0.9879 - val_accuracy: 0.7303 - 21s/epoch - 1s/step\n",
      "Epoch 32/100\n",
      "17/17 - 21s - loss: 2.1797 - accuracy: 0.3591 - val_loss: 0.8568 - val_accuracy: 0.7697 - 21s/epoch - 1s/step\n",
      "Epoch 33/100\n",
      "17/17 - 21s - loss: 2.1401 - accuracy: 0.3785 - val_loss: 0.8815 - val_accuracy: 0.7472 - 21s/epoch - 1s/step\n",
      "Epoch 34/100\n",
      "17/17 - 21s - loss: 2.1501 - accuracy: 0.3664 - val_loss: 0.9536 - val_accuracy: 0.7640 - 21s/epoch - 1s/step\n",
      "Epoch 35/100\n",
      "17/17 - 22s - loss: 2.1695 - accuracy: 0.3603 - val_loss: 0.8462 - val_accuracy: 0.7697 - 22s/epoch - 1s/step\n",
      "Epoch 36/100\n",
      "17/17 - 21s - loss: 2.1247 - accuracy: 0.3688 - val_loss: 0.8834 - val_accuracy: 0.7697 - 21s/epoch - 1s/step\n",
      "Epoch 37/100\n",
      "17/17 - 21s - loss: 2.0963 - accuracy: 0.3930 - val_loss: 0.8891 - val_accuracy: 0.7528 - 21s/epoch - 1s/step\n",
      "Epoch 38/100\n",
      "17/17 - 22s - loss: 2.1317 - accuracy: 0.3603 - val_loss: 0.9530 - val_accuracy: 0.7528 - 22s/epoch - 1s/step\n",
      "Epoch 39/100\n",
      "17/17 - 21s - loss: 2.1348 - accuracy: 0.3543 - val_loss: 0.8674 - val_accuracy: 0.7978 - 21s/epoch - 1s/step\n",
      "Epoch 40/100\n",
      "17/17 - 22s - loss: 2.1847 - accuracy: 0.3567 - val_loss: 0.8173 - val_accuracy: 0.7809 - 22s/epoch - 1s/step\n",
      "Epoch 41/100\n",
      "17/17 - 21s - loss: 2.1581 - accuracy: 0.3712 - val_loss: 0.8295 - val_accuracy: 0.8090 - 21s/epoch - 1s/step\n",
      "Epoch 42/100\n",
      "17/17 - 22s - loss: 2.1453 - accuracy: 0.3628 - val_loss: 0.8088 - val_accuracy: 0.7584 - 22s/epoch - 1s/step\n",
      "Epoch 43/100\n",
      "17/17 - 21s - loss: 2.1810 - accuracy: 0.3458 - val_loss: 0.8541 - val_accuracy: 0.7809 - 21s/epoch - 1s/step\n",
      "Epoch 44/100\n",
      "17/17 - 21s - loss: 2.1781 - accuracy: 0.3434 - val_loss: 0.8297 - val_accuracy: 0.7865 - 21s/epoch - 1s/step\n",
      "Epoch 45/100\n",
      "17/17 - 21s - loss: 2.0436 - accuracy: 0.3942 - val_loss: 0.8338 - val_accuracy: 0.7753 - 21s/epoch - 1s/step\n",
      "Epoch 46/100\n",
      "17/17 - 21s - loss: 2.1430 - accuracy: 0.3603 - val_loss: 0.8302 - val_accuracy: 0.8146 - 21s/epoch - 1s/step\n",
      "Epoch 47/100\n",
      "17/17 - 21s - loss: 2.2004 - accuracy: 0.3398 - val_loss: 0.9394 - val_accuracy: 0.7921 - 21s/epoch - 1s/step\n",
      "Epoch 48/100\n",
      "17/17 - 21s - loss: 2.1174 - accuracy: 0.3700 - val_loss: 0.8681 - val_accuracy: 0.7753 - 21s/epoch - 1s/step\n",
      "Epoch 49/100\n",
      "17/17 - 21s - loss: 2.0764 - accuracy: 0.3833 - val_loss: 0.9005 - val_accuracy: 0.7584 - 21s/epoch - 1s/step\n",
      "Epoch 50/100\n",
      "17/17 - 22s - loss: 2.1071 - accuracy: 0.3773 - val_loss: 0.7949 - val_accuracy: 0.7865 - 22s/epoch - 1s/step\n",
      "Epoch 51/100\n",
      "17/17 - 21s - loss: 2.0796 - accuracy: 0.3712 - val_loss: 0.8160 - val_accuracy: 0.7753 - 21s/epoch - 1s/step\n",
      "Epoch 52/100\n",
      "17/17 - 21s - loss: 2.0991 - accuracy: 0.3930 - val_loss: 0.8619 - val_accuracy: 0.7697 - 21s/epoch - 1s/step\n",
      "Epoch 53/100\n",
      "17/17 - 21s - loss: 2.1129 - accuracy: 0.3712 - val_loss: 0.8230 - val_accuracy: 0.7921 - 21s/epoch - 1s/step\n",
      "Epoch 54/100\n",
      "17/17 - 21s - loss: 2.0946 - accuracy: 0.3640 - val_loss: 0.9286 - val_accuracy: 0.7697 - 21s/epoch - 1s/step\n",
      "Epoch 55/100\n",
      "17/17 - 21s - loss: 2.0663 - accuracy: 0.3833 - val_loss: 0.9922 - val_accuracy: 0.7416 - 21s/epoch - 1s/step\n",
      "Epoch 56/100\n",
      "17/17 - 22s - loss: 2.0486 - accuracy: 0.3797 - val_loss: 1.1377 - val_accuracy: 0.7416 - 22s/epoch - 1s/step\n",
      "Epoch 57/100\n",
      "17/17 - 22s - loss: 2.0417 - accuracy: 0.3990 - val_loss: 0.9137 - val_accuracy: 0.7640 - 22s/epoch - 1s/step\n",
      "Epoch 58/100\n",
      "17/17 - 21s - loss: 2.0630 - accuracy: 0.3845 - val_loss: 0.9793 - val_accuracy: 0.7472 - 21s/epoch - 1s/step\n",
      "Epoch 59/100\n",
      "17/17 - 21s - loss: 2.1328 - accuracy: 0.3688 - val_loss: 0.9789 - val_accuracy: 0.7472 - 21s/epoch - 1s/step\n",
      "Epoch 60/100\n",
      "17/17 - 21s - loss: 2.0723 - accuracy: 0.3748 - val_loss: 0.9045 - val_accuracy: 0.7809 - 21s/epoch - 1s/step\n",
      "Epoch 61/100\n",
      "17/17 - 22s - loss: 2.1692 - accuracy: 0.3495 - val_loss: 0.8401 - val_accuracy: 0.7921 - 22s/epoch - 1s/step\n",
      "Epoch 62/100\n",
      "17/17 - 21s - loss: 2.0642 - accuracy: 0.3748 - val_loss: 0.9682 - val_accuracy: 0.7697 - 21s/epoch - 1s/step\n",
      "Epoch 63/100\n",
      "17/17 - 21s - loss: 2.0651 - accuracy: 0.3821 - val_loss: 0.8829 - val_accuracy: 0.7528 - 21s/epoch - 1s/step\n",
      "Epoch 64/100\n",
      "17/17 - 21s - loss: 2.0887 - accuracy: 0.3809 - val_loss: 0.8407 - val_accuracy: 0.7865 - 21s/epoch - 1s/step\n",
      "Epoch 65/100\n",
      "17/17 - 21s - loss: 2.0637 - accuracy: 0.3894 - val_loss: 1.0636 - val_accuracy: 0.7809 - 21s/epoch - 1s/step\n",
      "Epoch 66/100\n",
      "17/17 - 21s - loss: 2.0824 - accuracy: 0.3821 - val_loss: 0.8362 - val_accuracy: 0.7865 - 21s/epoch - 1s/step\n",
      "Epoch 67/100\n",
      "17/17 - 21s - loss: 2.0592 - accuracy: 0.3567 - val_loss: 1.0254 - val_accuracy: 0.7416 - 21s/epoch - 1s/step\n",
      "Epoch 68/100\n",
      "17/17 - 21s - loss: 2.0414 - accuracy: 0.3857 - val_loss: 0.9689 - val_accuracy: 0.7640 - 21s/epoch - 1s/step\n",
      "Epoch 69/100\n",
      "17/17 - 21s - loss: 2.0975 - accuracy: 0.3591 - val_loss: 0.7839 - val_accuracy: 0.8146 - 21s/epoch - 1s/step\n",
      "Epoch 70/100\n",
      "17/17 - 21s - loss: 2.0647 - accuracy: 0.3591 - val_loss: 0.8711 - val_accuracy: 0.8034 - 21s/epoch - 1s/step\n",
      "Epoch 71/100\n",
      "17/17 - 21s - loss: 2.1324 - accuracy: 0.3543 - val_loss: 0.7486 - val_accuracy: 0.8146 - 21s/epoch - 1s/step\n",
      "Epoch 72/100\n",
      "17/17 - 22s - loss: 2.0393 - accuracy: 0.3724 - val_loss: 0.8267 - val_accuracy: 0.7978 - 22s/epoch - 1s/step\n",
      "Epoch 73/100\n",
      "17/17 - 21s - loss: 2.1197 - accuracy: 0.3676 - val_loss: 0.9027 - val_accuracy: 0.7865 - 21s/epoch - 1s/step\n",
      "Epoch 74/100\n",
      "17/17 - 21s - loss: 2.0157 - accuracy: 0.3966 - val_loss: 1.0001 - val_accuracy: 0.7978 - 21s/epoch - 1s/step\n",
      "Epoch 75/100\n",
      "17/17 - 21s - loss: 2.0268 - accuracy: 0.3857 - val_loss: 0.8854 - val_accuracy: 0.8034 - 21s/epoch - 1s/step\n",
      "Epoch 76/100\n",
      "17/17 - 21s - loss: 2.0493 - accuracy: 0.3833 - val_loss: 0.8187 - val_accuracy: 0.8146 - 21s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Early stopping is being performed on val_accuracy with mode max. This means the metric being monitored is \n",
    "# validation accuracy(or validation error) and on max(or min) value of it. restore_best_weights selects the model with max validation accuracy. \n",
    "# This ensures that best model is the one with lowest validation error (1-accuracy)\n",
    "\n",
    "epochs = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience = 30, restore_best_weights=True, mode = \"max\")\n",
    "ds_train = preprocess_input(ds_train) \n",
    "ds_val = preprocess_input(ds_val)\n",
    "hist_vgg = vgg_model.fit(datagen.flow(ds_train, ds_train_label, batch_size=50), \n",
    "                           epochs=epochs, validation_data=(ds_val, ds_val_label), \n",
    "                           verbose=2, \n",
    "                           batch_size = 50,\n",
    "                           callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "7iIh0f0RW2oD",
    "outputId": "8e6e41b2-85b5-425c-b1d7-e0beb788ff7a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist_error(hist_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeJBy168jsoy"
   },
   "source": [
    "(v) Report Precision, Recall, and F1 score for your model. Remember that this\n",
    "is a multi-class classfication problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDpZ8kOAj103"
   },
   "source": [
    "##### Train metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQidAKtPjyDJ",
    "outputId": "feafc148-1233-4a64-d398-5ef1aa9082bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 8s 154ms/step\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           005.Crested_Auklet       0.86      0.97      0.91        31\n",
      "                 013.Bobolink       1.00      0.74      0.85        42\n",
      "           015.Lazuli_Bunting       0.85      0.98      0.91        41\n",
      "         023.Brandt_Cormorant       0.95      0.88      0.91        42\n",
      "   040.Olive_sided_Flycatcher       0.71      0.83      0.77        42\n",
      "041.Scissor_tailed_Flycatcher       0.91      0.98      0.94        42\n",
      "         067.Anna_Hummingbird       1.00      0.90      0.95        42\n",
      "          072.Pomarine_Jaeger       0.92      0.83      0.88        42\n",
      "          076.Dark_eyed_Junco       0.85      0.95      0.90        42\n",
      "          081.Pied_Kingfisher       0.98      0.98      0.98        42\n",
      "        082.Ringed_Kingfisher       0.97      0.88      0.93        42\n",
      "             086.Pacific_Loon       0.88      1.00      0.93        42\n",
      "                 099.Ovenbird       0.91      0.76      0.83        42\n",
      "           104.American_Pipit       0.81      0.83      0.82        42\n",
      "         127.Savannah_Sparrow       0.84      0.90      0.87        42\n",
      "             135.Bank_Swallow       0.74      0.83      0.79        42\n",
      "               141.Artic_Tern       0.95      0.90      0.92        41\n",
      "           149.Brown_Thrasher       0.89      0.93      0.91        42\n",
      "         156.White_eyed_Vireo       0.90      0.88      0.89        42\n",
      "         168.Kentucky_Warbler       1.00      0.86      0.92        42\n",
      "\n",
      "                     accuracy                           0.89       827\n",
      "                    macro avg       0.90      0.89      0.89       827\n",
      "                 weighted avg       0.90      0.89      0.89       827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(vgg_model, ds_train, ds_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lx7bw-KTj5qH"
   },
   "source": [
    "##### Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5C1S4uQDbexz",
    "outputId": "ad2ddce3-1768-4731-b815-df5abd3044df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 439ms/step\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           005.Crested_Auklet       0.86      1.00      0.92         6\n",
      "                 013.Bobolink       1.00      0.33      0.50         9\n",
      "           015.Lazuli_Bunting       0.88      0.88      0.88         8\n",
      "         023.Brandt_Cormorant       1.00      0.88      0.93         8\n",
      "   040.Olive_sided_Flycatcher       0.67      0.89      0.76         9\n",
      "041.Scissor_tailed_Flycatcher       0.75      1.00      0.86         9\n",
      "         067.Anna_Hummingbird       1.00      0.89      0.94         9\n",
      "          072.Pomarine_Jaeger       0.70      0.78      0.74         9\n",
      "          076.Dark_eyed_Junco       0.56      1.00      0.72         9\n",
      "          081.Pied_Kingfisher       0.88      0.78      0.82         9\n",
      "        082.Ringed_Kingfisher       1.00      0.78      0.88         9\n",
      "             086.Pacific_Loon       0.90      1.00      0.95         9\n",
      "                 099.Ovenbird       0.80      0.89      0.84         9\n",
      "           104.American_Pipit       0.67      0.89      0.76         9\n",
      "         127.Savannah_Sparrow       0.64      0.78      0.70         9\n",
      "             135.Bank_Swallow       0.67      0.50      0.57         8\n",
      "               141.Artic_Tern       1.00      0.88      0.93         8\n",
      "           149.Brown_Thrasher       0.75      0.38      0.50         8\n",
      "         156.White_eyed_Vireo       0.67      0.44      0.53         9\n",
      "         168.Kentucky_Warbler       0.71      0.62      0.67         8\n",
      "\n",
      "                     accuracy                           0.78       171\n",
      "                    macro avg       0.80      0.78      0.77       171\n",
      "                 weighted avg       0.80      0.78      0.77       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_test = preprocess_input(ds_test)\n",
    "model_evaluation(vgg_model, ds_test, ds_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbqSSOHDAIxG"
   },
   "source": [
    "##### Results Summarized \n",
    "\n",
    "##### Transfer learning with EfficientNetB0 for Image Classification - \n",
    "The following metrics are for Train dataset (not augmented)\n",
    "1. The model has precision of 0.99 and recall of 0.99\n",
    "2. The model has accuracy and f1 score of 0.99\n",
    "\n",
    "The following metrics are for Test dataset\n",
    "1. The model has precision of 0.91 and recall of 0.91\n",
    "2. The model has accuracy of 0.91 and f1 score of 0.91\n",
    "\n",
    "\n",
    "##### Transfer learning with VGG16 for Image Classification - \n",
    "The following metrics are for Train dataset (not augmented)\n",
    "1. The model has precision of 0.90 and recall of 0.89\n",
    "2. The model has accuracy of 0.89 and f1 score of 0.89\n",
    "\n",
    "The following metrics are for Test dataset\n",
    "1. The model has precision of 0.80 and recall of 0.78\n",
    "2. The model has accuracy of 0.78 and f1 score of 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj2OYPx2BwLF"
   },
   "source": [
    "##### References \n",
    "\n",
    "https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "\n",
    "https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
